akka.persistence {
  journal {
    plugin = "akka.persistence.journal.linq2db"
    linq2db {
      class = "Akka.Persistence.Sql.Linq2Db.Journal.Linq2DbWriteJournal, Akka.Persistence.Sql.Linq2Db"
      plugin-dispatcher = "akka.persistence.dispatchers.default-plugin-dispatcher"
      connection-string = "" # Connection String is Required!

      # Provider name is required.
      # Refer to LinqToDb.ProviderName for values
      # Always use a specific version if possible
      # To avoid provider detection performance penalty
      # Don't worry if your DB is newer than what is listed;
      # Just pick the newest one (if yours is still newer)
      provider-name = ""

      # If True, Deletes are done by updating Journal records
      # Rather than actual physical deletions
      logical-delete = false

      # If true, journal_metadata is created and used for deletes
      # and max sequence number queries.
      # note that there is a performance penalty for using this.
      delete-compatibility-mode = true

      # If "sqlite", "sqlserver", or "postgres", default column names are compatible with
      # Akka.Persistence.Sql Default Column names.                       
      table-compatibility-mode = null

      #If more entries than this are pending, writes will be rejected.
      #This setting is higher than JDBC because smaller batch sizes
      #Work better in testing and we want to add more buffer to make up
      #For that penalty. 
      buffer-size = 5000

      #Batch size refers to the number of items included in a batch to DB
      #  (In cases where an AtomicWrite is greater than batch-size,
      #   The Atomic write will still be handled in a single batch.)
      #JDBC Default is/was 400 but testing against scenarios indicates
      #100 is better for overall latency. That said,
      #larger batches may be better if you have A fast/local DB.
      batch-size = 100

      #This batch size controls the maximum number of rows that will be sent
      #In a single round trip to the DB. This is different than the -actual- batch size,
      #And intentionally set larger than batch-size,
      #to help atomicwrites be faster
      #Note that Linq2Db may use a lower number per round-trip in some cases. 
      db-round-trip-max-batch-size = 1000

      #Linq2Db by default will use a built string for multi-row inserts
      #Somewhat counterintuitively, this is faster than using parameters in most cases,
      #But if you would prefer parameters, you can set this to true.
      prefer-parameters-on-multirow-insert = true

      # Denotes the number of messages retrieved
      # Per round-trip to DB on recovery.
      # This is to limit both size of dataset from DB (possibly lowering locking requirements)
      # As well as limit memory usage on journal retrieval in CLR
      replay-batch-size = 1000

      # Number of Concurrennt writers.
      # On larger servers with more cores you can increase this number
      # But in most cases 2-4 is a safe bet. 
      parallelism = 3

      #If a batch is larger than this number,
      #Plugin will utilize Linq2db's
      #Default bulk copy rather than row-by-row.
      #Currently this setting only really has an impact on
      #SQL Server and IBM Informix (If someone decides to test that out)
      #SQL Server testing indicates that under this number of rows, (or thereabouts,)
      #MultiRow is faster than Row-By-Row.
      max-row-by-row-size = 100

      #Only set to TRUE if unit tests pass with the connection string you intend to use!
      #This setting will go away once https://github.com/linq2db/linq2db/issues/2466 is resolved
      use-clone-connection = false

      # This dispatcher will be used for the Stream Materializers
      # Note that while all calls will be Async to Linq2Db,
      # If your provider for some reason does not support async,
      # or you are a very heavily loaded system,
      # You may wish to provide a dedicated dispatcher instead
      materializer-dispatcher = "akka.actor.default-dispatcher"
      
      tables.journal {

        #if delete-compatibility-mode is true, both tables are created
        #if delete-compatibility-mode is false, only journal table will be created.
        auto-init = true

        table-name = "journal"
        metadata-table-name = "journal_metadata"

        #If you want to specify a schema for your tables, you can do so here.
        schema-name = null



        column-names {
          "ordering" = "ordering"
          "deleted" = "deleted"
          "persistenceId" = "persistence_id"
          "sequenceNumber" = "sequence_number"
          "created" = "created"
          "tags" = "tags"
          "message" = "message"
          "identifier" = "identifier"
          "manifest" = "manifest"
        }
        sqlserver-compat-column-names {
          "ordering" = "ordering"
          "deleted" = "isdeleted"
          "persistenceId" = "persistenceId"
          "sequenceNumber" = "sequenceNr"
          "created" = "Timestamp"
          "tags" = "tags"
          "message" = "payload"
          "identifier" = "serializerid"
          "manifest" = "manifest"
        }
        sqlite-compat-column-names {
          "ordering" = "ordering"
          "deleted" = "is_deleted"
          "persistenceId" = "persistence_Id"
          "sequenceNumber" = "sequence_nr"
          "created" = "Timestamp"
          "tags" = "tags"
          "message" = "payload"
          "identifier" = "serializer_id"
          "manifest" = "manifest"
        }
        postgres-compat-column-names {
          "ordering" = "ordering"
          "deleted" = "is_deleted"
          "persistenceId" = "persistence_id"
          "sequenceNumber" = "sequence_nr"
          "created" = "created_at"
          "tags" = "tags"
          "message" = "payload"
          "identifier" = "serializer_id"
          "manifest" = "manifest"
        }
        metadata-column-names {
          "persistenceId" = "persistenceId"
          "sequenceNumber" = "sequenceNr"
        }
        sqlserver-compat-metadata-column-names {
          "persistenceId" = "persistenceId"
          "sequenceNumber" = "sequenceNr"
        }
        sqlite-compat-metadata-column-names {
          "persistenceId" = "persistence_Id"
          "sequenceNumber" = "sequence_nr"
        }
        postgres-compat-metadata-column-names {
          "persistenceId" = "persistence_id"
          "sequenceNumber" = "sequence_nr"
        }
      }
    }
  }
  query {
    journal {
      linq2db {
        class = "Akka.Persistence.Sql.Linq2Db.Query.Linq2DbReadJournalProvider, Akka.Persistence.Sql.Linq2Db"

        #You should specify your proper linq2db journal plugin configuration path here.
        write-plugin = ""

        include-logically-deleted = true # whether to include logical deletes in query results

        max-buffer-size = 500 # Number of events to buffer at a time.
        refresh-interval = 1s # interval for refreshing


        connection-string = "" # Connection String is Required!

        journal-sequence-retrieval{
          batch-size = 10000
          max-tries = 10
          query-delay = 1s
          max-backoff-query-delay = 60s
          ask-timeout = 1s
        }

        # Provider name is required.
        # Refer to LinqToDb.ProviderName for values
        # Always use a specific version if possible
        # To avoid provider detection performance penalty
        # Don't worry if your DB is newer than what is listed;
        # Just pick the newest one (if yours is still newer)
        provider-name = ""

        # If True, Deletes are done by updating Journal records
        # Rather than actual physical deletions
        logical-delete = false

        # If true, journal_metadata is created
        delete-compatibility-mode = true

        # If "sqlite" or "sqlserver", default column names are compatible with
        # Akka.Persistence.Sql Default Column names.                       
        table-compatibility-mode = null

        #If more entries than this are pending, writes will be rejected.
        #This setting is higher than JDBC because smaller batch sizes
        #Work better in testing and we want to add more buffer to make up
        #For that penalty. 
        buffer-size = 5000

        #Batch size refers to the number of items included in a batch to DB
        #JDBC Default is/was 400 but testing against scenarios indicates
        #100 is better for overall latency. That said,
        #larger batches may be better if you have A fast/local DB.
        batch-size = 100

        # Denotes the number of messages retrieved
        # Per round-trip to DB on recovery.
        # This is to limit both size of dataset from DB (possibly lowering locking requirements)
        # As well as limit memory usage on journal retrieval in CLR
        replay-batch-size = 1000

        # Number of Concurrennt writers.
        # On larger servers with more cores you can increase this number
        # But in most cases 2-4 is a safe bet. 
        parallelism = 3

        #If a batch is larger than this number,
        #Plugin will utilize Linq2db's
        #Default bulk copy rather than row-by-row.
        #Currently this setting only really has an impact on
        #SQL Server and IBM Informix (If someone decides to test that out)
        #SQL Server testing indicates that under this number of rows, (or thereabouts,)
        #MultiRow is faster than Row-By-Row.
        max-row-by-row-size = 100

        #Only set to TRUE if unit tests pass with the connection string you intend to use!
        #This setting will go away once https://github.com/linq2db/linq2db/issues/2466 is resolved
        use-clone-connection = false

        tables.journal {

          #if delete-compatibility-mode is true, both tables are created
          #if delete-compatibility-mode is false, only journal table will be created.
          auto-init = true

          #if true, a warning will be logged
          #if auto-init of tables fails.
          #set to false if you don't want this warning logged
          #perhaps if running CI tests or similar.
          warn-on-auto-init-fail = true

          table-name = "journal"
          metadata-table-name = "journal_metadata"

          #If you want to specify a schema for your tables, you can do so here.
          schema-name = null


          column-names {
            "ordering" = "ordering"
            "deleted" = "deleted"
            "persistenceId" = "persistence_id"
            "sequenceNumber" = "sequence_number"
            "created" = "created"
            "tags" = "tags"
            "message" = "message"
            "identifier" = "identifier"
            "manifest" = "manifest"
          }
          sqlserver-compat-column-names {
            "ordering" = "ordering"
            "deleted" = "isdeleted"
            "persistenceId" = "persistenceId"
            "sequenceNumber" = "sequenceNr"
            "created" = "Timestamp"
            "tags" = "tags"
            "message" = "payload"
            "identifier" = "serializerid"
            "manifest" = "manifest"
          }
          sqlite-compat-column-names {
            "ordering" = "ordering"
            "deleted" = "is_deleted"
            "persistenceId" = "persistence_Id"
            "sequenceNumber" = "sequence_nr"
            "created" = "Timestamp"
            "tags" = "tags"
            "message" = "payload"
            "identifier" = "serializer_id"
            "manifest" = "manifest"
          }
          postgres-compat-column-names {
            "ordering" = "ordering"
            "deleted" = "is_deleted"
            "persistenceId" = "persistence_id"
            "sequenceNumber" = "sequence_nr"
            "created" = "created_at"
            "tags" = "tags"
            "message" = "payload"
            "identifier" = "serializer_id"
            "manifest" = "manifest"
          }
          metadata-column-names {
            "persistenceId" = "persistenceId"
            "sequenceNumber" = "sequenceNr"
          }
          sqlserver-compat-metadata-column-names {
            "persistenceId" = "persistenceId"
            "sequenceNumber" = "sequenceNr"
          }
          sqlite-compat-metadata-column-names {
            "persistenceId" = "persistence_Id"
            "sequenceNumber" = "sequence_nr"
          }
          postgres-compat-metadata-column-names {
            "persistenceId" = "persistence_id"
            "sequenceNumber" = "sequence_nr"
          }
        }
      }
    }
  }
}